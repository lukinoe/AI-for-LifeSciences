{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data_train.csv\")\n",
    "test = pd.read_csv(\"./smiles_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels = \"Unnamed: 0\", axis = 1)\n",
    "df = df[(df == 0).sum(1) < 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11531, 11)\n"
     ]
    }
   ],
   "source": [
    "smiles = df[\"smiles\"].to_list()\n",
    "y = df.drop(labels = \"smiles\", axis = 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Morgan Fingerprints\n",
    "def get_morgan_df(smiles):\n",
    "    from rdkit.Chem import AllChem\n",
    "\n",
    "    mutag = [Chem.rdmolfiles.MolFromSmiles(smile) for smile in smiles]\n",
    "\n",
    "    # Initialize variables\n",
    "    fp_length = 2048\n",
    "    desc_mtx = np.zeros((len(mutag), fp_length)) * np.nan\n",
    "    compounds = [''] * len(mutag)\n",
    "\n",
    "    # Calculate Morgan fingerprints (equivalent to ECFP fingerprints)\n",
    "    for i, mol in enumerate(mutag): \n",
    "        if mol is not None:\n",
    "            desc_mtx[i] = AllChem.GetMorganFingerprintAsBitVect(mol, radius=3, nBits=fp_length)\n",
    "            \n",
    "    return pd.DataFrame(desc_mtx)\n",
    "\n",
    "df = get_morgan_df(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11531, 2048) (11531, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train = df\n",
    "y_train = y\n",
    "\n",
    "X_train = X_train.reset_index(drop=True).fillna(0)\n",
    "y_train = y_train.reset_index(drop=True).fillna(0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5896, 2048)\n"
     ]
    }
   ],
   "source": [
    "submission_x = get_morgan_df(test[\"smiles\"].to_list())\n",
    "\n",
    "print(submission_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Model 0 ------------------------\n",
      "Data Shape: (1010, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.6296296296296295\n",
      " \n",
      "Model 1 ------------------------\n",
      "Data Shape: (1023, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.8609022556390977\n",
      " \n",
      "Model 2 ------------------------\n",
      "Data Shape: (1314, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 11.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.8430773705642816\n",
      " \n",
      "Model 3 ------------------------\n",
      "Data Shape: (953, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.7957650273224044\n",
      " \n",
      "Model 4 ------------------------\n",
      "Data Shape: (632, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.5782108945527236\n",
      " \n",
      "Model 5 ------------------------\n",
      "Data Shape: (632, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.7578065498857578\n",
      " \n",
      "Model 6 ------------------------\n",
      "Data Shape: (610, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.7744252873563219\n",
      " \n",
      "Model 7 ------------------------\n",
      "Data Shape: (3804, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 61.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.7667878787878788\n",
      " \n",
      "Model 8 ------------------------\n",
      "Data Shape: (3626, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 70.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.8123752989726494\n",
      " \n",
      "Model 9 ------------------------\n",
      "Data Shape: (4311, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed: 85.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.7803190567019247\n",
      " \n",
      "Model 10 ------------------------\n",
      "Data Shape: (962, 2048)\n",
      " \n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC:  0.5428808339256102\n",
      "\n",
      "Mean Test ROC:  0.7401981893943891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, VotingClassifier, GradientBoostingClassifier, AdaBoostClassifier,BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "models = {}\n",
    "rocs = []\n",
    "\n",
    "for i,col in enumerate(y_train.columns):\n",
    "    \n",
    "    y = y_train[col]\n",
    "    idx = y.index[y != 0].tolist()\n",
    "    y = y[idx]\n",
    "    x = X_train.iloc[idx]\n",
    "            \n",
    "    print(\" \")\n",
    "    print(\"Model \" + str(i) + \" ------------------------\")\n",
    "    print(\"Data Shape: \" + str(x.shape))\n",
    "    print(\" \")\n",
    "    \n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(x, y, test_size=0.2)\n",
    "    \n",
    "    param_grid = {\n",
    "        'C': [0.1,1, 10, 100], \n",
    "        'gamma': [1,0.1,0.01,0.001],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "    \n",
    "    svr_grid = GridSearchCV(SVR(), param_grid,refit=True,verbose=1, scoring=\"roc_auc\")\n",
    "    \n",
    "    grid_fit = svr_grid.fit(X_train_, y_train_)  \n",
    "    best_svr = grid_fit.best_estimator_\n",
    "    best_params = grid_fit.best_params_\n",
    "    svr = SVR(**best_params)\n",
    "            \n",
    "    bagg = BaggingRegressor(base_estimator=svr, n_estimators=20)\n",
    "    bagg.fit(X_train_, y_train_)\n",
    "    \n",
    "    yhat = bagg.predict(X_test_)\n",
    "    \n",
    "    rocs.append(roc_auc_score(y_test_, yhat))\n",
    "    \n",
    "    models[i] = bagg\n",
    "    \n",
    "    print(\"Test ROC: \" , roc_auc_score(y_test_, yhat))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Mean Test ROC: \",np.mean(np.array(rocs)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: BaggingRegressor(base_estimator=SVR(C=10, gamma=0.01), n_estimators=20), 1: BaggingRegressor(base_estimator=SVR(C=1, gamma=0.01), n_estimators=20), 2: BaggingRegressor(base_estimator=SVR(C=0.1, gamma=1, kernel='poly'),\n",
      "                 n_estimators=20), 3: BaggingRegressor(base_estimator=SVR(C=100, gamma=0.01), n_estimators=20), 4: BaggingRegressor(base_estimator=SVR(C=1, gamma=0.001, kernel='poly'),\n",
      "                 n_estimators=20), 5: BaggingRegressor(base_estimator=SVR(C=1, gamma=0.01), n_estimators=20), 6: BaggingRegressor(base_estimator=SVR(C=0.1, gamma=1, kernel='poly'),\n",
      "                 n_estimators=20), 7: BaggingRegressor(base_estimator=SVR(C=1, gamma=0.01, kernel='poly'),\n",
      "                 n_estimators=20), 8: BaggingRegressor(base_estimator=SVR(C=100, gamma=0.01, kernel='poly'),\n",
      "                 n_estimators=20), 9: BaggingRegressor(base_estimator=SVR(C=0.1, gamma=0.1, kernel='poly'),\n",
      "                 n_estimators=20), 10: BaggingRegressor(base_estimator=SVR(C=10, gamma=0.1), n_estimators=20)}\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[[-0.50566973 -0.81771095 -0.85482851 ... -0.90875603 -0.97884474\n",
      "  -1.09038967]\n",
      " [-1.36646857 -1.19016865 -0.6491894  ... -1.09301409 -1.19518814\n",
      "  -0.4838124 ]\n",
      " [ 0.76173464  0.78194426  0.88570303 ...  0.60241105  0.60764155\n",
      "   0.40640542]\n",
      " ...\n",
      " [-0.86430336 -0.78518741  0.60295353 ... -0.34159936  0.26833769\n",
      "  -0.90372738]\n",
      " [-0.87555986 -0.85488401 -0.85012871 ... -0.84411905 -0.85987544\n",
      "  -0.91467408]\n",
      " [ 0.27135269  0.14831885  0.31945759 ...  0.04988117  0.15023683\n",
      "   0.31141644]] (11, 5896)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "print(models)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print(i)\n",
    "\n",
    "    y_hat = models[i].predict(submission_x)\n",
    "    predictions.append(y_hat)\n",
    "    \n",
    "print(np.array(predictions), np.array(predictions).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "predictions_ = np.array(predictions).reshape((predictions.shape[0], predictions.shape[1]))\n",
    "predictions_ = pd.DataFrame(predictions_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_.columns = y_train.columns\n",
    "predictions_.to_csv(\"subm_20_04_21_50.csv\", float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
