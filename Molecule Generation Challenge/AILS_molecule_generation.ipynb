{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Elg31loQMrOd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "\n",
    "# url=\"https://apps.ml.jku.at/challenge/data/datasets/mol_generation/smiles_train.txt\"\n",
    "# txt_file=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PHispHWQdMF",
    "outputId": "59620897-bbe5-478f-8c34-471053284044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "4/1AY0e-g7i60E3QFPOc0Np349J1FsxsiaFpy422RkpHZbH3razmTx-EgSVev0\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMd70pY1MyS6"
   },
   "outputs": [],
   "source": [
    "# with open('somefile.txt', 'a') as the_file:\n",
    "#     for line in lines[:20000]:\n",
    "#       the_file.write(line)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T14bTqbqNOIF"
   },
   "outputs": [],
   "source": [
    "# val = pd.read_csv(\"/content/drive/MyDrive/AILS_mol_generation/smiles_val_lu.txt\")[\"0\"].to_list()\n",
    "# print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHcnmBK6RWdI"
   },
   "source": [
    "Preprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86HLh495Od37"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TextDS(Dataset):\n",
    "    def __init__(self, text_file: PosixPath, seq_length: int, batch_size: int, vocabs= None):\n",
    "        self.vocab_input = vocabs\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.input_txt = open(text_file, encoding=\"utf-8\").readlines()[:100000]\n",
    "        print(len(self.input_txt))\n",
    "        self.input_txt = ' '.join(self.input_txt)\n",
    "        self.txt_data = self.cleanse()\n",
    "\n",
    "        self.torch_sequences, self.vocabs, self.idx2char, self.char2idx = self.chars(seq_length)\n",
    "        print(1)\n",
    "        self.torch_sequences = self.yield_sequence_split()\n",
    "        self.datagen = self.get_datagenerator()\n",
    "        \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_torch)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.torch_sequences[idx]\n",
    "    \n",
    "    def cleanse(self):\n",
    "        \n",
    "        txt_data = self.input_txt.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').lower()\n",
    "        \n",
    "        charset_to_delete = []\n",
    "        for i in charset_to_delete:\n",
    "            txt_data = txt_data.replace(i , '')  \n",
    "                    \n",
    "        return txt_data\n",
    "    \n",
    "    def chars(self, seq_length):\n",
    "        if self.vocab_input != None:\n",
    "            vocab = self.vocab_input\n",
    "        else:\n",
    "            vocab = sorted(set(self.txt_data))\n",
    "        \n",
    "        char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "        idx2char = np.array(vocab)\n",
    "\n",
    "        text_as_int = np.array([char2idx[c] for c in self.txt_data])\n",
    "        \n",
    "        print('{} ---- characters mapped to int ---- > {}'.format(repr(self.txt_data[:13]), text_as_int[:13]))\n",
    "        print('Vocab size: ' + str(len(vocab)))\n",
    "        \n",
    "        length = seq_length\n",
    "        sequences = list()\n",
    "        for i in range(length, len(text_as_int)):\n",
    "            # select sequence of tokens\n",
    "            seq = text_as_int[i-length:i+1]\n",
    "            # store\n",
    "            sequences.append(seq)\n",
    "            \n",
    "                \n",
    "        sequences = torch.tensor(sequences).to(device)\n",
    "        \n",
    "        return sequences, vocab, idx2char, char2idx\n",
    "    \n",
    "    def yield_sequence_split(self):\n",
    "        \n",
    "        l = []\n",
    "        \n",
    "        for seq in self.torch_sequences:\n",
    "            input_example, target_example = self.split_input_target(seq)\n",
    "            l.append([input_example, target_example[-1]])\n",
    "\n",
    "        print(\"Datasize: \", len(l))\n",
    "        \n",
    "        return l     \n",
    "        \n",
    "    def get_datagenerator(self):\n",
    "        \n",
    "        datagen = torch.utils.data.DataLoader(self.torch_sequences, batch_size=self.batch_size)\n",
    "        return datagen\n",
    "\n",
    "    def split_input_target(self, chunk):\n",
    "        input_text = chunk[:-1]\n",
    "        target_text = chunk[1:]\n",
    "        return input_text, target_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw2cDxLUR9rM"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size, output_size, n_of_classes, seq_length, LR=0.001, momentum= 0.9):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_of_classes = n_of_classes\n",
    "        \n",
    "        self.z = nn.Linear(input_size, hidden_size)\n",
    "        self.z_rec = nn.Linear(hidden_size,hidden_size) \n",
    "        self.z_tanh = nn.Tanh()\n",
    "        \n",
    "        self.i = nn.Linear(input_size, hidden_size)\n",
    "        self.i_rec = nn.Linear(hidden_size, hidden_size)\n",
    "        self.i_sigmoid = nn.Sigmoid()\n",
    "                \n",
    "        self.o = nn.Linear(input_size, hidden_size)\n",
    "        self.o_rec = nn.Linear(hidden_size, hidden_size)\n",
    "        self.o_sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.c_tanh = nn.Tanh()\n",
    "        \n",
    "        self.h0 = torch.zeros((hidden_size)).type(torch.float)\n",
    "        self.c0 = torch.zeros((hidden_size)).type(torch.float)\n",
    "        \n",
    "        self.V = nn.Linear(hidden_size, n_of_classes)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        #self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=8, gamma=0.1)\n",
    "        self.current_loss = []\n",
    "\n",
    "        self.apply(self._weights_init) # not for forget gate (needs init with high bias)\n",
    "\n",
    "        # initialize forget gate with high bias\n",
    "        self.f = nn.Linear(input_size, hidden_size)\n",
    "        self.f.bias.data.fill_(10)\n",
    "        self.f_rec = nn.Linear(hidden_size, hidden_size)\n",
    "        self.f_rec.bias.data.fill_(10)\n",
    "        self.f_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    @staticmethod\n",
    "    def _weights_init(m):\n",
    "      if isinstance(m, nn.Linear):          \n",
    "        nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain(\"relu\")),\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch) -> torch.Tensor:\n",
    "         \n",
    "        batch_size = len(batch)\n",
    "        seq_len = batch.shape[1]\n",
    "        \n",
    "        self.h0 = torch.zeros((batch_size, hidden_size)).type(torch.float).to(device)\n",
    "        self.c0 = torch.zeros((batch_size, hidden_size)).type(torch.float).to(device)\n",
    "        \n",
    "\n",
    "        for i in range(seq_len):\n",
    "\n",
    "            x= batch[:,i,:]\n",
    "            \n",
    "            y_z = self.z_tanh(self.z(x) + self.z_rec(self.h0))\n",
    "            y_i = self.i_sigmoid(self.i(x) + self.i_rec(self.h0))\n",
    "            y_f = self.f_sigmoid(self.f(x) + self.f_rec(self.h0))\n",
    "\n",
    "            c = y_f * self.c0 + y_z * y_i\n",
    "            self.c0 = c.detach()\n",
    "\n",
    "            y_c = self.c_tanh(c)\n",
    "            y_o = self.o_sigmoid(self.o(x) + self.o_rec(self.h0))\n",
    "\n",
    "            y = y_c * y_o\n",
    "            self.h0 = y.detach()  # rec. y; detach grad attribute\n",
    "        \n",
    "        y = self.V(y)  # puts y into the right shape for cross entropy\n",
    "             \n",
    "        return y\n",
    "    \n",
    "    def print_grads(self):\n",
    "        print(sum(self.z.weight.grad))\n",
    "    \n",
    "    def reset_loss(self):\n",
    "        self.current_loss = []\n",
    "        \n",
    "    def backward(self, y_hat, y):\n",
    "        loss_ = self.loss(y_hat, y)\n",
    "        loss_.backward(retain_graph=True)\n",
    "  \n",
    "        self.current_loss.append(loss_.detach())\n",
    "        \n",
    "    def update(self):\n",
    "        self.optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHg6TnlLM3d6"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Model_(nn.Module):\n",
    "    def __init__(self, input_size: int, n_hidden, output_size, n_of_classes, seq_length, LR=0.001, momentum= 0.9, drop_prob=0, n_layers=1):\n",
    "        super(Model_, self).__init__()\n",
    "        \n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "\n",
    "\n",
    "        #LSTM Layers\n",
    "        self.lstm = nn.LSTM(n_of_classes, self.n_hidden, self.n_layers,\n",
    "                           dropout=self.drop_prob, batch_first=True)\n",
    "\n",
    "        #Dropout Layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "        ##Fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, output_size)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LR, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        #self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=8, gamma=0.1)\n",
    "        self.current_loss = []\n",
    "\n",
    "        self.apply(self._weights_init) # not for forget gate (needs init with high bias)\n",
    "\n",
    "    @staticmethod\n",
    "    def _weights_init(m):\n",
    "      if isinstance(m, nn.Linear):          \n",
    "        nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain(\"relu\")),\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "\n",
    "        batch_size = len(x)\n",
    "\n",
    "        self.h0 = torch.zeros((self.n_layers, batch_size, self.n_hidden)).type(torch.float).to(device)\n",
    "        self.c0 = torch.zeros((self.n_layers, batch_size, self.n_hidden)).type(torch.float).to(device)\n",
    "\n",
    "        hidden = (self.h0, self.c0)\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "\n",
    "        out = self.dropout(r_output)\n",
    "        out = out[:,-1,:]\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def print_grads(self):\n",
    "        print(sum(self.z.weight.grad))\n",
    "    \n",
    "    def reset_loss(self):\n",
    "        self.current_loss = []\n",
    "        \n",
    "    def backward(self, y_hat, y):\n",
    "        loss_ = self.loss(y_hat, y)\n",
    "        loss_.backward(retain_graph=True)\n",
    "  \n",
    "        self.current_loss.append(loss_.detach())\n",
    "        \n",
    "    def update(self):\n",
    "        self.optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxLjHWD1SOFn",
    "outputId": "9bcbe7a5-03d8-4165-f57a-1b48e325332e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "'o=c1c(=cc2ccc' ---- characters mapped to int ---- > [28 17 21  8 21  3 17 21 21  9 21 21 21]\n",
      "Vocab size: 32\n",
      "1\n",
      "Datasize:  4859892\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "seq_length_ = 24\n",
    "batch_size_ = 128\n",
    "lr = 0.001\n",
    "hidden_size = 1024\n",
    "epochs = 10\n",
    "n_layers= 2\n",
    "drop_prob = 0.2\n",
    "\n",
    "data = TextDS(\"/content/drive/MyDrive/AILS_mol_generation/smiles_train.txt\", seq_length_, batch_size_, None)\n",
    "#data_validation = TextDS('sample_data/trump_val.txt', seq_length_, batch_size_, data.vocabs) #use vocab idx of train\n",
    "\n",
    "data_ = torch.load(\"/content/drive/MyDrive/AILS_mol_generation/torch_sequences_4859892\")  \n",
    "      \n",
    "_train_data = data_[:4459892]\n",
    "_val_data = data_[4459892:]\n",
    "\n",
    "datagen = torch.utils.data.DataLoader(_train_data, batch_size=batch_size_)\n",
    "datagen_validation = torch.utils.data.DataLoader(_val_data, batch_size=batch_size_)\n",
    "\n",
    "\n",
    "n_of_classes = len(data.vocabs)\n",
    "sequence_length = data.seq_length\n",
    "\n",
    "input_size = n_of_classes\n",
    "hidden_size = hidden_size\n",
    "output_size = n_of_classes\n",
    "\n",
    "\n",
    "m = Model_(input_size, hidden_size, output_size, n_of_classes, sequence_length, lr, n_layers=2, drop_prob=drop_prob)\n",
    "m.to(device) #enable cuda\n",
    "\n",
    "loss_list = list()\n",
    "valid_loss_list = []\n",
    "accuracy_list = list()\n",
    "correct = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHP1WHprSZTZ",
    "outputId": "e0ffb301-a62b-45a3-e237-7240802a0506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000, Loss: 1.353, Accuracy: 0.571\n",
      "Step: 2000, Loss: 1.028, Accuracy: 0.657\n",
      "Step: 3000, Loss: 0.956, Accuracy: 0.676\n",
      "Step: 4000, Loss: 0.923, Accuracy: 0.686\n",
      "Step: 5000, Loss: 0.899, Accuracy: 0.692\n",
      "Step: 6000, Loss: 0.873, Accuracy: 0.7\n",
      "Step: 7000, Loss: 0.862, Accuracy: 0.704\n",
      "Step: 8000, Loss: 0.855, Accuracy: 0.707\n",
      "Step: 9000, Loss: 0.847, Accuracy: 0.709\n",
      "Step: 10000, Loss: 0.832, Accuracy: 0.714\n",
      "Step: 11000, Loss: 0.825, Accuracy: 0.714\n",
      "Step: 12000, Loss: 0.818, Accuracy: 0.718\n",
      "Step: 13000, Loss: 0.814, Accuracy: 0.717\n",
      "Step: 14000, Loss: 0.813, Accuracy: 0.72\n",
      "Step: 15000, Loss: 0.806, Accuracy: 0.723\n",
      "Step: 16000, Loss: 0.803, Accuracy: 0.723\n",
      "Step: 17000, Loss: 0.798, Accuracy: 0.724\n",
      "Step: 18000, Loss: 0.797, Accuracy: 0.724\n",
      "Step: 19000, Loss: 0.786, Accuracy: 0.728\n",
      "Step: 20000, Loss: 0.787, Accuracy: 0.728\n",
      "Step: 21000, Loss: 0.785, Accuracy: 0.728\n",
      "Step: 22000, Loss: 0.782, Accuracy: 0.729\n",
      "Step: 23000, Loss: 0.779, Accuracy: 0.73\n",
      "Step: 24000, Loss: 0.774, Accuracy: 0.732\n",
      "Step: 25000, Loss: 0.774, Accuracy: 0.733\n",
      "Step: 26000, Loss: 0.771, Accuracy: 0.732\n",
      "Step: 27000, Loss: 0.777, Accuracy: 0.731\n",
      "Step: 28000, Loss: 0.765, Accuracy: 0.734\n",
      "Step: 29000, Loss: 0.771, Accuracy: 0.731\n",
      "Step: 30000, Loss: 0.764, Accuracy: 0.735\n",
      "Step: 31000, Loss: 0.77, Accuracy: 0.734\n",
      "Step: 32000, Loss: 0.762, Accuracy: 0.735\n",
      "Step: 33000, Loss: 0.764, Accuracy: 0.736\n",
      "Step: 34000, Loss: 0.765, Accuracy: 0.734\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid. Loss:tensor(0.7586, device='cuda:0')\n",
      "Step: 1000, Loss: 0.755, Accuracy: 0.738\n",
      "Step: 2000, Loss: 0.748, Accuracy: 0.74\n",
      "Step: 3000, Loss: 0.75, Accuracy: 0.738\n",
      "Step: 4000, Loss: 0.756, Accuracy: 0.738\n",
      "Step: 5000, Loss: 0.749, Accuracy: 0.74\n",
      "Step: 6000, Loss: 0.744, Accuracy: 0.741\n",
      "Step: 7000, Loss: 0.746, Accuracy: 0.74\n",
      "Step: 8000, Loss: 0.745, Accuracy: 0.742\n",
      "Step: 9000, Loss: 0.745, Accuracy: 0.741\n",
      "Step: 10000, Loss: 0.741, Accuracy: 0.743\n",
      "Step: 11000, Loss: 0.738, Accuracy: 0.743\n",
      "Step: 12000, Loss: 0.734, Accuracy: 0.744\n",
      "Step: 13000, Loss: 0.735, Accuracy: 0.742\n",
      "Step: 14000, Loss: 0.736, Accuracy: 0.743\n",
      "Step: 15000, Loss: 0.733, Accuracy: 0.746\n",
      "Step: 16000, Loss: 0.73, Accuracy: 0.745\n",
      "Step: 17000, Loss: 0.731, Accuracy: 0.746\n",
      "Step: 18000, Loss: 0.732, Accuracy: 0.745\n",
      "Step: 19000, Loss: 0.724, Accuracy: 0.748\n",
      "Step: 20000, Loss: 0.725, Accuracy: 0.748\n",
      "Step: 21000, Loss: 0.724, Accuracy: 0.747\n",
      "Step: 22000, Loss: 0.722, Accuracy: 0.747\n",
      "Step: 23000, Loss: 0.721, Accuracy: 0.749\n",
      "Step: 24000, Loss: 0.719, Accuracy: 0.749\n",
      "Step: 25000, Loss: 0.721, Accuracy: 0.749\n",
      "Step: 26000, Loss: 0.72, Accuracy: 0.748\n",
      "Step: 27000, Loss: 0.725, Accuracy: 0.746\n",
      "Step: 28000, Loss: 0.715, Accuracy: 0.75\n",
      "Step: 29000, Loss: 0.721, Accuracy: 0.747\n",
      "Step: 30000, Loss: 0.718, Accuracy: 0.749\n",
      "Step: 31000, Loss: 0.722, Accuracy: 0.748\n",
      "Step: 32000, Loss: 0.714, Accuracy: 0.751\n",
      "Step: 33000, Loss: 0.718, Accuracy: 0.749\n",
      "Step: 34000, Loss: 0.72, Accuracy: 0.748\n",
      "\n",
      "Epoch 2\n",
      "Valid. Loss:tensor(0.7280, device='cuda:0')\n",
      "Step: 1000, Loss: 0.712, Accuracy: 0.751\n",
      "Step: 2000, Loss: 0.705, Accuracy: 0.754\n",
      "Step: 3000, Loss: 0.708, Accuracy: 0.752\n",
      "Step: 4000, Loss: 0.715, Accuracy: 0.75\n",
      "Step: 5000, Loss: 0.706, Accuracy: 0.753\n",
      "Step: 6000, Loss: 0.706, Accuracy: 0.753\n",
      "Step: 7000, Loss: 0.705, Accuracy: 0.754\n",
      "Step: 8000, Loss: 0.707, Accuracy: 0.753\n",
      "Step: 9000, Loss: 0.706, Accuracy: 0.753\n",
      "Step: 10000, Loss: 0.703, Accuracy: 0.754\n",
      "Step: 11000, Loss: 0.702, Accuracy: 0.755\n",
      "Step: 12000, Loss: 0.698, Accuracy: 0.755\n",
      "Step: 13000, Loss: 0.699, Accuracy: 0.753\n",
      "Step: 14000, Loss: 0.701, Accuracy: 0.755\n",
      "Step: 15000, Loss: 0.7, Accuracy: 0.755\n",
      "Step: 16000, Loss: 0.697, Accuracy: 0.756\n",
      "Step: 17000, Loss: 0.697, Accuracy: 0.756\n",
      "Step: 18000, Loss: 0.698, Accuracy: 0.756\n",
      "Step: 19000, Loss: 0.692, Accuracy: 0.758\n",
      "Step: 20000, Loss: 0.694, Accuracy: 0.757\n",
      "Step: 21000, Loss: 0.693, Accuracy: 0.757\n",
      "Step: 22000, Loss: 0.69, Accuracy: 0.757\n",
      "Step: 23000, Loss: 0.689, Accuracy: 0.759\n",
      "Step: 24000, Loss: 0.689, Accuracy: 0.759\n",
      "Step: 25000, Loss: 0.689, Accuracy: 0.759\n",
      "Step: 26000, Loss: 0.691, Accuracy: 0.757\n",
      "Step: 27000, Loss: 0.694, Accuracy: 0.756\n",
      "Step: 28000, Loss: 0.686, Accuracy: 0.759\n",
      "Step: 29000, Loss: 0.691, Accuracy: 0.757\n",
      "Step: 30000, Loss: 0.69, Accuracy: 0.758\n",
      "Step: 31000, Loss: 0.696, Accuracy: 0.756\n",
      "Step: 32000, Loss: 0.688, Accuracy: 0.758\n",
      "Step: 33000, Loss: 0.689, Accuracy: 0.758\n",
      "Step: 34000, Loss: 0.691, Accuracy: 0.758\n",
      "\n",
      "Epoch 3\n",
      "Valid. Loss:tensor(0.7162, device='cuda:0')\n",
      "Step: 1000, Loss: 0.684, Accuracy: 0.76\n",
      "Step: 2000, Loss: 0.678, Accuracy: 0.763\n",
      "Step: 3000, Loss: 0.681, Accuracy: 0.761\n",
      "Step: 4000, Loss: 0.691, Accuracy: 0.758\n",
      "Step: 5000, Loss: 0.682, Accuracy: 0.761\n",
      "Step: 6000, Loss: 0.681, Accuracy: 0.761\n",
      "Step: 7000, Loss: 0.681, Accuracy: 0.761\n",
      "Step: 8000, Loss: 0.683, Accuracy: 0.76\n",
      "Step: 9000, Loss: 0.684, Accuracy: 0.76\n",
      "Step: 10000, Loss: 0.68, Accuracy: 0.762\n",
      "Step: 11000, Loss: 0.68, Accuracy: 0.76\n",
      "Step: 12000, Loss: 0.675, Accuracy: 0.762\n",
      "Step: 13000, Loss: 0.679, Accuracy: 0.76\n",
      "Step: 14000, Loss: 0.68, Accuracy: 0.762\n",
      "Step: 15000, Loss: 0.678, Accuracy: 0.763\n",
      "Step: 16000, Loss: 0.676, Accuracy: 0.762\n",
      "Step: 17000, Loss: 0.675, Accuracy: 0.763\n",
      "Step: 18000, Loss: 0.677, Accuracy: 0.764\n",
      "Step: 19000, Loss: 0.671, Accuracy: 0.765\n",
      "Step: 20000, Loss: 0.672, Accuracy: 0.764\n",
      "Step: 21000, Loss: 0.671, Accuracy: 0.763\n",
      "Step: 22000, Loss: 0.67, Accuracy: 0.762\n",
      "Step: 23000, Loss: 0.669, Accuracy: 0.765\n",
      "Step: 24000, Loss: 0.672, Accuracy: 0.764\n",
      "Step: 25000, Loss: 0.671, Accuracy: 0.765\n",
      "Step: 26000, Loss: 0.672, Accuracy: 0.763\n",
      "Step: 27000, Loss: 0.675, Accuracy: 0.763\n",
      "Step: 28000, Loss: 0.667, Accuracy: 0.765\n",
      "Step: 29000, Loss: 0.671, Accuracy: 0.763\n",
      "Step: 30000, Loss: 0.67, Accuracy: 0.763\n",
      "Step: 31000, Loss: 0.677, Accuracy: 0.762\n",
      "Step: 32000, Loss: 0.668, Accuracy: 0.764\n",
      "Step: 33000, Loss: 0.674, Accuracy: 0.763\n",
      "Step: 34000, Loss: 0.673, Accuracy: 0.764\n",
      "\n",
      "Epoch 4\n",
      "Valid. Loss:tensor(0.7115, device='cuda:0')\n",
      "Step: 1000, Loss: 0.666, Accuracy: 0.765\n",
      "Step: 2000, Loss: 0.662, Accuracy: 0.767\n",
      "Step: 3000, Loss: 0.665, Accuracy: 0.766\n",
      "Step: 4000, Loss: 0.673, Accuracy: 0.763\n",
      "Step: 5000, Loss: 0.664, Accuracy: 0.767\n",
      "Step: 6000, Loss: 0.665, Accuracy: 0.765\n",
      "Step: 7000, Loss: 0.664, Accuracy: 0.765\n",
      "Step: 8000, Loss: 0.666, Accuracy: 0.766\n",
      "Step: 9000, Loss: 0.667, Accuracy: 0.765\n",
      "Step: 10000, Loss: 0.663, Accuracy: 0.767\n",
      "Step: 11000, Loss: 0.662, Accuracy: 0.766\n",
      "Step: 12000, Loss: 0.659, Accuracy: 0.768\n",
      "Step: 13000, Loss: 0.664, Accuracy: 0.766\n",
      "Step: 14000, Loss: 0.662, Accuracy: 0.767\n",
      "Step: 15000, Loss: 0.663, Accuracy: 0.768\n",
      "Step: 16000, Loss: 0.662, Accuracy: 0.767\n",
      "Step: 17000, Loss: 0.662, Accuracy: 0.767\n",
      "Step: 18000, Loss: 0.662, Accuracy: 0.768\n",
      "Step: 19000, Loss: 0.657, Accuracy: 0.768\n",
      "Step: 20000, Loss: 0.659, Accuracy: 0.768\n",
      "Step: 21000, Loss: 0.656, Accuracy: 0.767\n",
      "Step: 22000, Loss: 0.655, Accuracy: 0.767\n",
      "Step: 23000, Loss: 0.655, Accuracy: 0.769\n",
      "Step: 24000, Loss: 0.658, Accuracy: 0.769\n",
      "Step: 25000, Loss: 0.658, Accuracy: 0.769\n",
      "Step: 26000, Loss: 0.657, Accuracy: 0.767\n",
      "Step: 27000, Loss: 0.662, Accuracy: 0.767\n",
      "Step: 28000, Loss: 0.654, Accuracy: 0.769\n",
      "Step: 29000, Loss: 0.658, Accuracy: 0.768\n",
      "Step: 30000, Loss: 0.657, Accuracy: 0.769\n",
      "Step: 31000, Loss: 0.662, Accuracy: 0.766\n",
      "Step: 32000, Loss: 0.654, Accuracy: 0.769\n",
      "Step: 33000, Loss: 0.658, Accuracy: 0.768\n",
      "Step: 34000, Loss: 0.659, Accuracy: 0.768\n",
      "\n",
      "Epoch 5\n",
      "Valid. Loss:tensor(0.7075, device='cuda:0')\n",
      "Step: 1000, Loss: 0.654, Accuracy: 0.77\n",
      "Step: 2000, Loss: 0.649, Accuracy: 0.772\n",
      "Step: 3000, Loss: 0.65, Accuracy: 0.771\n",
      "Step: 4000, Loss: 0.661, Accuracy: 0.768\n",
      "Step: 5000, Loss: 0.652, Accuracy: 0.771\n",
      "Step: 6000, Loss: 0.652, Accuracy: 0.77\n",
      "Step: 7000, Loss: 0.651, Accuracy: 0.771\n",
      "Step: 8000, Loss: 0.653, Accuracy: 0.77\n",
      "Step: 9000, Loss: 0.653, Accuracy: 0.769\n",
      "Step: 10000, Loss: 0.651, Accuracy: 0.771\n",
      "Step: 11000, Loss: 0.65, Accuracy: 0.77\n",
      "Step: 12000, Loss: 0.648, Accuracy: 0.77\n",
      "Step: 13000, Loss: 0.651, Accuracy: 0.769\n",
      "Step: 14000, Loss: 0.649, Accuracy: 0.771\n",
      "Step: 15000, Loss: 0.651, Accuracy: 0.772\n",
      "Step: 16000, Loss: 0.649, Accuracy: 0.771\n",
      "Step: 17000, Loss: 0.647, Accuracy: 0.772\n",
      "Step: 18000, Loss: 0.65, Accuracy: 0.77\n",
      "Step: 19000, Loss: 0.645, Accuracy: 0.772\n",
      "Step: 20000, Loss: 0.645, Accuracy: 0.772\n",
      "Step: 21000, Loss: 0.646, Accuracy: 0.772\n",
      "Step: 22000, Loss: 0.644, Accuracy: 0.771\n",
      "Step: 23000, Loss: 0.643, Accuracy: 0.773\n",
      "Step: 24000, Loss: 0.645, Accuracy: 0.772\n",
      "Step: 25000, Loss: 0.645, Accuracy: 0.773\n",
      "Step: 26000, Loss: 0.646, Accuracy: 0.771\n",
      "Step: 27000, Loss: 0.65, Accuracy: 0.771\n",
      "Step: 28000, Loss: 0.643, Accuracy: 0.773\n",
      "Step: 29000, Loss: 0.645, Accuracy: 0.771\n",
      "Step: 30000, Loss: 0.646, Accuracy: 0.771\n",
      "Step: 31000, Loss: 0.652, Accuracy: 0.769\n",
      "Step: 32000, Loss: 0.644, Accuracy: 0.771\n",
      "Step: 33000, Loss: 0.648, Accuracy: 0.771\n",
      "Step: 34000, Loss: 0.647, Accuracy: 0.771\n",
      "\n",
      "Epoch 6\n",
      "Valid. Loss:tensor(0.7057, device='cuda:0')\n",
      "Step: 1000, Loss: 0.639, Accuracy: 0.774\n",
      "Step: 2000, Loss: 0.638, Accuracy: 0.775\n",
      "Step: 3000, Loss: 0.64, Accuracy: 0.775\n",
      "Step: 4000, Loss: 0.65, Accuracy: 0.77\n",
      "Step: 5000, Loss: 0.642, Accuracy: 0.774\n",
      "Step: 6000, Loss: 0.642, Accuracy: 0.774\n",
      "Step: 7000, Loss: 0.639, Accuracy: 0.774\n",
      "Step: 8000, Loss: 0.64, Accuracy: 0.775\n",
      "Step: 9000, Loss: 0.641, Accuracy: 0.773\n",
      "Step: 10000, Loss: 0.641, Accuracy: 0.773\n",
      "Step: 11000, Loss: 0.64, Accuracy: 0.773\n",
      "Step: 12000, Loss: 0.638, Accuracy: 0.774\n",
      "Step: 13000, Loss: 0.639, Accuracy: 0.773\n",
      "Step: 14000, Loss: 0.641, Accuracy: 0.774\n",
      "Step: 15000, Loss: 0.64, Accuracy: 0.774\n",
      "Step: 16000, Loss: 0.639, Accuracy: 0.774\n",
      "Step: 17000, Loss: 0.637, Accuracy: 0.775\n",
      "Step: 18000, Loss: 0.638, Accuracy: 0.774\n",
      "Step: 19000, Loss: 0.632, Accuracy: 0.776\n",
      "Step: 20000, Loss: 0.635, Accuracy: 0.775\n",
      "Step: 21000, Loss: 0.635, Accuracy: 0.775\n",
      "Step: 22000, Loss: 0.632, Accuracy: 0.776\n",
      "Step: 23000, Loss: 0.632, Accuracy: 0.777\n",
      "Step: 24000, Loss: 0.637, Accuracy: 0.775\n",
      "Step: 25000, Loss: 0.635, Accuracy: 0.776\n",
      "Step: 26000, Loss: 0.636, Accuracy: 0.775\n",
      "Step: 27000, Loss: 0.64, Accuracy: 0.773\n",
      "Step: 28000, Loss: 0.632, Accuracy: 0.776\n",
      "Step: 29000, Loss: 0.635, Accuracy: 0.775\n",
      "Step: 30000, Loss: 0.636, Accuracy: 0.774\n",
      "Step: 31000, Loss: 0.642, Accuracy: 0.773\n",
      "Step: 32000, Loss: 0.633, Accuracy: 0.776\n",
      "Step: 33000, Loss: 0.639, Accuracy: 0.774\n",
      "Step: 34000, Loss: 0.637, Accuracy: 0.774\n",
      "\n",
      "Epoch 7\n",
      "Valid. Loss:tensor(0.7071, device='cuda:0')\n",
      "Step: 1000, Loss: 0.631, Accuracy: 0.776\n",
      "Step: 2000, Loss: 0.63, Accuracy: 0.777\n",
      "Step: 3000, Loss: 0.63, Accuracy: 0.778\n",
      "Step: 4000, Loss: 0.642, Accuracy: 0.773\n",
      "Step: 5000, Loss: 0.631, Accuracy: 0.777\n",
      "Step: 6000, Loss: 0.632, Accuracy: 0.775\n",
      "Step: 7000, Loss: 0.63, Accuracy: 0.777\n",
      "Step: 8000, Loss: 0.631, Accuracy: 0.777\n",
      "Step: 9000, Loss: 0.633, Accuracy: 0.775\n",
      "Step: 10000, Loss: 0.631, Accuracy: 0.776\n",
      "Step: 11000, Loss: 0.63, Accuracy: 0.777\n",
      "Step: 12000, Loss: 0.629, Accuracy: 0.777\n",
      "Step: 13000, Loss: 0.629, Accuracy: 0.776\n",
      "Step: 14000, Loss: 0.632, Accuracy: 0.776\n",
      "Step: 15000, Loss: 0.63, Accuracy: 0.776\n",
      "Step: 16000, Loss: 0.629, Accuracy: 0.777\n",
      "Step: 17000, Loss: 0.627, Accuracy: 0.778\n",
      "Step: 18000, Loss: 0.63, Accuracy: 0.778\n",
      "Step: 19000, Loss: 0.626, Accuracy: 0.779\n",
      "Step: 20000, Loss: 0.626, Accuracy: 0.778\n",
      "Step: 21000, Loss: 0.625, Accuracy: 0.778\n",
      "Step: 22000, Loss: 0.623, Accuracy: 0.778\n",
      "Step: 23000, Loss: 0.624, Accuracy: 0.78\n",
      "Step: 24000, Loss: 0.626, Accuracy: 0.778\n",
      "Step: 25000, Loss: 0.626, Accuracy: 0.779\n",
      "Step: 26000, Loss: 0.627, Accuracy: 0.778\n",
      "Step: 27000, Loss: 0.631, Accuracy: 0.776\n",
      "Step: 28000, Loss: 0.623, Accuracy: 0.78\n",
      "Step: 29000, Loss: 0.626, Accuracy: 0.777\n",
      "Step: 30000, Loss: 0.629, Accuracy: 0.777\n",
      "Step: 31000, Loss: 0.632, Accuracy: 0.776\n",
      "Step: 32000, Loss: 0.623, Accuracy: 0.778\n",
      "Step: 33000, Loss: 0.628, Accuracy: 0.777\n",
      "Step: 34000, Loss: 0.628, Accuracy: 0.777\n",
      "\n",
      "Epoch 8\n",
      "Valid. Loss:tensor(0.7057, device='cuda:0')\n",
      "Step: 1000, Loss: 0.621, Accuracy: 0.78\n",
      "Step: 2000, Loss: 0.623, Accuracy: 0.78\n",
      "Step: 3000, Loss: 0.622, Accuracy: 0.779\n",
      "Step: 4000, Loss: 0.632, Accuracy: 0.777\n",
      "Step: 5000, Loss: 0.624, Accuracy: 0.779\n",
      "Step: 6000, Loss: 0.624, Accuracy: 0.779\n",
      "Step: 7000, Loss: 0.62, Accuracy: 0.78\n",
      "Step: 8000, Loss: 0.623, Accuracy: 0.78\n",
      "Step: 9000, Loss: 0.624, Accuracy: 0.778\n",
      "Step: 10000, Loss: 0.623, Accuracy: 0.78\n",
      "Step: 11000, Loss: 0.622, Accuracy: 0.779\n",
      "Step: 12000, Loss: 0.619, Accuracy: 0.779\n",
      "Step: 13000, Loss: 0.622, Accuracy: 0.778\n",
      "Step: 14000, Loss: 0.623, Accuracy: 0.779\n",
      "Step: 15000, Loss: 0.623, Accuracy: 0.78\n",
      "Step: 16000, Loss: 0.621, Accuracy: 0.779\n",
      "Step: 17000, Loss: 0.62, Accuracy: 0.78\n",
      "Step: 18000, Loss: 0.621, Accuracy: 0.779\n",
      "Step: 19000, Loss: 0.615, Accuracy: 0.781\n",
      "Step: 20000, Loss: 0.617, Accuracy: 0.78\n",
      "Step: 21000, Loss: 0.617, Accuracy: 0.78\n",
      "Step: 22000, Loss: 0.615, Accuracy: 0.78\n",
      "Step: 23000, Loss: 0.615, Accuracy: 0.781\n",
      "Step: 24000, Loss: 0.619, Accuracy: 0.78\n",
      "Step: 25000, Loss: 0.618, Accuracy: 0.781\n",
      "Step: 26000, Loss: 0.617, Accuracy: 0.781\n",
      "Step: 27000, Loss: 0.624, Accuracy: 0.778\n",
      "Step: 28000, Loss: 0.616, Accuracy: 0.782\n",
      "Step: 29000, Loss: 0.617, Accuracy: 0.78\n",
      "Step: 30000, Loss: 0.618, Accuracy: 0.781\n",
      "Step: 31000, Loss: 0.624, Accuracy: 0.778\n",
      "Step: 32000, Loss: 0.615, Accuracy: 0.781\n",
      "Step: 33000, Loss: 0.619, Accuracy: 0.781\n",
      "Step: 34000, Loss: 0.619, Accuracy: 0.78\n",
      "\n",
      "Epoch 9\n",
      "Valid. Loss:tensor(0.7053, device='cuda:0')\n",
      "Step: 1000, Loss: 0.613, Accuracy: 0.782\n",
      "Step: 2000, Loss: 0.613, Accuracy: 0.783\n",
      "Step: 3000, Loss: 0.613, Accuracy: 0.782\n",
      "Step: 4000, Loss: 0.625, Accuracy: 0.779\n",
      "Step: 5000, Loss: 0.615, Accuracy: 0.783\n",
      "Step: 6000, Loss: 0.614, Accuracy: 0.782\n",
      "Step: 7000, Loss: 0.613, Accuracy: 0.782\n",
      "Step: 8000, Loss: 0.614, Accuracy: 0.782\n",
      "Step: 9000, Loss: 0.614, Accuracy: 0.781\n",
      "Step: 10000, Loss: 0.615, Accuracy: 0.782\n",
      "Step: 11000, Loss: 0.614, Accuracy: 0.781\n",
      "Step: 12000, Loss: 0.613, Accuracy: 0.782\n",
      "Step: 13000, Loss: 0.613, Accuracy: 0.781\n",
      "Step: 14000, Loss: 0.614, Accuracy: 0.782\n",
      "Step: 15000, Loss: 0.616, Accuracy: 0.783\n",
      "Step: 16000, Loss: 0.613, Accuracy: 0.782\n",
      "Step: 17000, Loss: 0.612, Accuracy: 0.783\n",
      "Step: 18000, Loss: 0.613, Accuracy: 0.783\n",
      "Step: 19000, Loss: 0.608, Accuracy: 0.783\n",
      "Step: 20000, Loss: 0.609, Accuracy: 0.784\n",
      "Step: 21000, Loss: 0.608, Accuracy: 0.783\n",
      "Step: 22000, Loss: 0.607, Accuracy: 0.783\n",
      "Step: 23000, Loss: 0.606, Accuracy: 0.784\n",
      "Step: 24000, Loss: 0.61, Accuracy: 0.783\n",
      "Step: 25000, Loss: 0.608, Accuracy: 0.785\n",
      "Step: 26000, Loss: 0.608, Accuracy: 0.784\n",
      "Step: 27000, Loss: 0.614, Accuracy: 0.781\n",
      "Step: 28000, Loss: 0.608, Accuracy: 0.783\n",
      "Step: 29000, Loss: 0.609, Accuracy: 0.783\n",
      "Step: 30000, Loss: 0.61, Accuracy: 0.783\n",
      "Step: 31000, Loss: 0.614, Accuracy: 0.781\n",
      "Step: 32000, Loss: 0.607, Accuracy: 0.785\n",
      "Step: 33000, Loss: 0.613, Accuracy: 0.782\n",
      "Step: 34000, Loss: 0.61, Accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print('')\n",
    "    print('Epoch ' + str(epoch))\n",
    "    \n",
    "    if epoch != 0:\n",
    "        loss_list.append((sum(m.current_loss) / len(m.current_loss)))\n",
    "        m.reset_loss()\n",
    "        \n",
    "        accuracy_list.append(sum(correct) / len(correct))\n",
    "        correct = []\n",
    "        \n",
    "    # *******  Validation ************#\n",
    "        valid_loss = []\n",
    "        with torch.no_grad():\n",
    "            for x_valid, target_valid in datagen_validation:\n",
    "                x_valid = nn.functional.one_hot(x_valid.type(torch.long), n_of_classes).type(torch.float)\n",
    "                y_hat_valid = m.forward(x_valid)  \n",
    "                y_valid = torch.tensor(target_valid.type(torch.long))\n",
    "                valid_loss.append(m.loss(y_hat_valid,y_valid))\n",
    "\n",
    "        print('Valid. Loss:' + str(sum(valid_loss) / len(valid_loss)))\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_loss = []\n",
    "        \n",
    "\n",
    "    # ********** Training *******************#\n",
    "    for step_idx, (x,target) in enumerate(datagen):\n",
    "               \n",
    "        m.optimizer.zero_grad()\n",
    "\n",
    "        x = nn.functional.one_hot(x.type(torch.long), n_of_classes).type(torch.float)\n",
    "        y_hat = m.forward(x)  \n",
    "        y = torch.tensor(target.type(torch.long))\n",
    "        \n",
    "        y_for_acc = torch.argmax(torch.nn.functional.softmax(y_hat.detach()).data, axis=1)\n",
    "        correct.append(torch.sum((y_for_acc == y).float()) / len(x))\n",
    "                \n",
    "        \n",
    "        m.backward(y_hat,y)\n",
    "        m.update()\n",
    "        \n",
    "        if step_idx % 1000 == 0 and step_idx != 0:\n",
    "            tmp = m.current_loss[-1000:]\n",
    "            print('Step: ' + str(step_idx)+ ', ' +'Loss: ' + str(round(float(sum(tmp) / len(tmp)),3)) + ', ' + 'Accuracy: ' + str(round(float(sum(correct[-1000:]) / 1000),3)) )  \n",
    "\n",
    "    torch.save(m, \"/content/drive/MyDrive/AILS_mol_generation/lstm_2_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLaN-UwH3pzZ"
   },
   "outputs": [],
   "source": [
    "def predict(_model, prime=\"C\", seq_length=24, top_k=1, n_of_chars=100, confidence=0.8):\n",
    "\n",
    "  def softmax_pred(X):\n",
    "      expo = torch.exp(X)\n",
    "      expo_sum = torch.sum(torch.exp(X))\n",
    "      soft = expo/expo_sum\n",
    "      pred = torch.argmax(soft)\n",
    "      if top_k > 1 and pred < confidence:                 # < 0.7 condition for only doing randomization only in unsure cases for text quality\n",
    "          vals, topk_idx = torch.topk(soft, top_k)\n",
    "          idx = torch.randint(0, top_k, (1,))\n",
    "          pred = topk_idx[0][idx]\n",
    "      return pred\n",
    "\n",
    "  for i in range(n_of_chars):\n",
    "\n",
    "      prime_len = len(prime)\n",
    "      if prime_len <= seq_length_: text_as_int = np.array([data.char2idx[c] for c in prime.lower()])\n",
    "      else: text_as_int = np.array([data.char2idx[c] for c in prime[-seq_length:].lower()])\n",
    "\n",
    "      text_one_hot = nn.functional.one_hot(torch.tensor(text_as_int).type(torch.long), n_of_classes).type(torch.float)\n",
    "      input_tensor = text_one_hot.reshape((1, text_one_hot.shape[0], text_one_hot.shape[1])).to(device)\n",
    "\n",
    "      if i % 2000 == 0:\n",
    "        print(i)\n",
    "\n",
    "      output = _model.forward(input_tensor).detach()\n",
    "      pred = softmax_pred(output.to(device))\n",
    "      char = data.idx2char[pred]\n",
    "      prime += char\n",
    "\n",
    "  return prime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "m34wCrPv14l5",
    "outputId": "bb1c6896-ea74-41aa-d6c3-86e3591a319a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "prime = \"C\"\n",
    "\n",
    "str_ = predict(m, prime=prime, top_k=3, seq_length=seq_length_, n_of_chars=10000, confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bH2MkN10zaXy",
    "outputId": "dccdffb7-a262-4111-ddf4-ee97e1be6d90"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'str_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-821d73016456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmols_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmols_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmols_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgen_mol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmols_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'str_' is not defined"
     ]
    }
   ],
   "source": [
    "mols_pred = str_.split(\" \")\n",
    "\n",
    "print(mols_pred)\n",
    "print(len(mols_pred))\n",
    "gen_mol = pd.DataFrame(mols_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXFakx-Au9hA"
   },
   "outputs": [],
   "source": [
    "m = torch.load(\"/content/drive/MyDrive/AILS_mol_generation/lstm_2_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHrqM65Bvjs7",
    "outputId": "d5f211e6-2845-45b2-d6aa-a6c975a95dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fcd\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/1d/75bf35ec742cbe679bfe373e5a0859a1debbd1bcc15d3cfa0930620438b2/FCD-1.1-py3-none-any.whl (53.1MB)\n",
      "\u001b[K     |████████████████████████████████| 53.1MB 98kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fcd) (1.4.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from fcd) (2.4.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from fcd) (2.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fcd) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.12)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (2.4.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (2.10.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (3.12.4)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.12.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (2.4.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->fcd) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->fcd) (3.13)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (56.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (1.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->fcd) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->fcd) (4.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->fcd) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->fcd) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->fcd) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->fcd) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->fcd) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->fcd) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->fcd) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->fcd) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->fcd) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->fcd) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->fcd) (3.1.0)\n",
      "Installing collected packages: fcd\n",
      "Successfully installed fcd-1.1\n",
      "Collecting rdkit-pypi\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/66/dcedc9498f7a3424d5acaeb97531992cc758f4219c870f95e38f9b6f58f3/rdkit_pypi-2021.3.1.4-cp37-cp37m-manylinux2014_x86_64.whl (32.8MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8MB 146kB/s \n",
      "\u001b[?25hInstalling collected packages: rdkit-pypi\n",
      "Successfully installed rdkit-pypi-2021.3.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install fcd\n",
    "!pip install rdkit-pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "-ostw1b6vmAl",
    "outputId": "09fa1141-0ade-42ff-fd67-50ee591e69d1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d2fa3e08c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#gen_mol = pd.read_csv(gen_mol_file,header=None)[0] #IMPORTANT: take at least 10000 molecules as FCD can vary with sample size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgen_mol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_mol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msample1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msample2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_mol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_mol' is not defined"
     ]
    }
   ],
   "source": [
    "from fcd import get_fcd, load_ref_model,canonical_smiles, get_predictions, calculate_frechet_distance\n",
    "#https://github.com/bioinf-jku/FCD/blob/master/example.ipynb\n",
    "\n",
    "#gen_mol = pd.read_csv(gen_mol_file,header=None)[0] #IMPORTANT: take at least 10000 molecules as FCD can vary with sample size \n",
    "gen_mol = gen_mol[0].to_list()\n",
    "sample1 = np.random.choice(gen_mol, 10000, replace=False)\n",
    "sample2 = np.random.choice(gen_mol, 10000, replace=False)\n",
    "\n",
    "# get canonical smiles and filter invalid ones\n",
    "can_sample1 = [w for w in canonical_smiles(sample1) if w is not None]\n",
    "can_sample2 = [w for w in canonical_smiles(sample2) if w is not None]\n",
    "\n",
    "\n",
    "#get CHEBMLNET activations of generated molecules \n",
    "act1 = get_predictions(model, can_sample1)\n",
    "act2 = get_predictions(model, can_sample2)\n",
    "\n",
    "mu1 = np.mean(act1, axis=0)\n",
    "sigma1 = np.cov(act1.T)\n",
    "\n",
    "mu2 = np.mean(act2, axis=0)\n",
    "sigma2 = np.cov(act2.T)\n",
    "\n",
    "fcd_score = calculate_frechet_distance(\n",
    "    mu1=mu1,\n",
    "    mu2=mu2, \n",
    "    sigma1=sigma1,\n",
    "    sigma2=sigma2)\n",
    "\n",
    "print('FCD: ',fcd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-NaI1qC0cu8"
   },
   "outputs": [],
   "source": [
    "def get_metric(list_):    \n",
    "\n",
    "    with open(\"/content/drive/MyDrive/AILS_mol_generation/smiles_train.txt\") as f:\n",
    "        smiles_train = {s for s in f.read().split() if s}\n",
    "\n",
    "    smiles_gen = list_[:10000]\n",
    "\n",
    "    smiles_can = canonical_smiles(smiles_gen)\n",
    "    smiles_valid = [s for s in smiles_can if s is not None]\n",
    "    smiles_unique = set(smiles_valid)\n",
    "    smiles_novel = smiles_unique - smiles_train\n",
    "\n",
    "    validity = len(smiles_valid) / len(smiles_gen)\n",
    "    uniqueness = len(smiles_unique) / len(smiles_gen)\n",
    "    novelty = len(smiles_novel) / len(smiles_gen)\n",
    "\n",
    "    # if name == 'validity':\n",
    "    #     return validity\n",
    "    # elif name == 'uniqueness':\n",
    "    #     return uniqueness\n",
    "    # elif name == 'novelty':\n",
    "    #     return novelty\n",
    "    # elif name != 'fcd':\n",
    "    #     raise ValueError('Invalid metric: %s' % name)\n",
    "\n",
    "    # Load precomputed test mean and covariance\n",
    "    with open(\"/content/drive/MyDrive/AILS_mol_generation/test_stats.p\", 'rb') as f:\n",
    "        mean_test, cov_test = pickle.load(f)\n",
    "\n",
    "    model = loadmodel()\n",
    "    mean_gen, cov_gen = getstats(smiles_valid, model)\n",
    "\n",
    "    fcd_value = fcd.calculate_frechet_distance(\n",
    "        mu1=mean_gen,\n",
    "        mu2=mean_test,\n",
    "        sigma1=cov_gen,\n",
    "        sigma2=cov_test)\n",
    "    return fcd_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPO78ExfB9u-"
   },
   "outputs": [],
   "source": [
    "f = open('/content/drive/MyDrive/AILS_mol_generation/submission.txt', \"r\")\n",
    "f = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdARmY4MFi-6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AILS_molecule_generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
